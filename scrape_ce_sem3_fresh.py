#!/usr/bin/env python3
"""
Fresh Data Scraper for CE Sem 3 using a simple but effective approach.
Scrapes GeeksforGeeks, TutorialsPoint, and JavaTpoint directly.
"""

import os
import re
import time
import requests
from bs4 import BeautifulSoup
from dotenv import load_dotenv
from supabase import create_client

load_dotenv()

# Initialize Supabase
supabase_url = os.getenv("SUPABASE_URL")
supabase_key = os.getenv("SUPABASE_KEY")
supabase = create_client(supabase_url, supabase_key)

# CE Sem 3 Subjects with URLs
CE_SEM3_SUBJECTS = [
    {
        "code": "3130702",
        "name": "Data Structures",
        "urls": {
            "geeksforgeeks": "https://www.geeksforgeeks.org/data-structures/",
            "tutorialspoint": "https://www.tutorialspoint.com/data_structures_algorithms/index.htm"
        },
        "topics": [
            "Arrays", "Linked Lists", "Stacks", "Queues", "Trees", "Binary Trees",
            "Binary Search Trees", "Graphs", "Hashing", "Sorting Algorithms",
            "Searching Algorithms", "Heap", "Recursion", "Dynamic Programming"
        ]
    },
    {
        "code": "3130703",
        "name": "Database Management Systems",
        "urls": {
            "geeksforgeeks": "https://www.geeksforgeeks.org/dbms/",
            "tutorialspoint": "https://www.tutorialspoint.com/dbms/index.htm"
        },
        "topics": [
            "Introduction to DBMS", "ER Model", "Relational Model", "SQL Queries",
            "Normalization", "Transactions", "Concurrency Control", "Database Recovery",
            "Indexing", "B-Trees", "Query Processing", "Joins", "Triggers"
        ]
    },
    {
        "code": "3130704",
        "name": "Digital Fundamentals",
        "urls": {
            "geeksforgeeks": "https://www.geeksforgeeks.org/digital-electronics-logic-design-tutorials/",
            "tutorialspoint": "https://www.tutorialspoint.com/digital_circuits/index.htm"
        },
        "topics": [
            "Number Systems", "Boolean Algebra", "Logic Gates", "Combinational Circuits",
            "Sequential Circuits", "Flip Flops", "Counters", "Registers",
            "Multiplexers", "Decoders", "Encoders", "Memory Devices"
        ]
    },
    {
        "code": "3130006",
        "name": "Probability and Statistics",
        "urls": {
            "geeksforgeeks": "https://www.geeksforgeeks.org/engineering-mathematics-tutorials/",
            "tutorialspoint": "https://www.tutorialspoint.com/statistics/index.htm"
        },
        "topics": [
            "Probability Basics", "Random Variables", "Probability Distributions",
            "Normal Distribution", "Binomial Distribution", "Poisson Distribution",
            "Mean Median Mode", "Standard Deviation", "Correlation", "Regression",
            "Hypothesis Testing", "Chi-Square Test"
        ]
    },
    {
        "code": "3130705",
        "name": "Object Oriented Programming",
        "urls": {
            "geeksforgeeks": "https://www.geeksforgeeks.org/cpp-tutorial/",
            "tutorialspoint": "https://www.tutorialspoint.com/cplusplus/index.htm"
        },
        "topics": [
            "Classes and Objects", "Inheritance", "Polymorphism", "Encapsulation",
            "Abstraction", "Constructors", "Destructors", "Operator Overloading",
            "Function Overloading", "Virtual Functions", "Templates", 
            "Exception Handling", "File Handling", "STL"
        ]
    }
]

def scrape_geeksforgeeks_topic(topic, subject_name):
    """Scrape a topic from GeeksforGeeks"""
    search_query = f"{topic} {subject_name}".replace(' ', '+')
    url = f"https://www.geeksforgeeks.org/tag/{topic.lower().replace(' ', '-')}/"
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
    }
    
    try:
        response = requests.get(url, headers=headers, timeout=10)
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # Get article content
            content = ""
            articles = soup.find_all(['article', 'div'], class_=['content', 'article-text'])
            for article in articles[:3]:
                content += article.get_text(strip=True)[:1000]
            
            if not content:
                # Fallback - get any text content
                paragraphs = soup.find_all('p')[:10]
                content = ' '.join([p.get_text(strip=True) for p in paragraphs])
            
            return content[:3000] if content else None
    except Exception as e:
        print(f"    Error scraping {topic}: {e}")
    
    return None

def scrape_tutorialspoint_topic(topic, subject_name, base_url):
    """Scrape a topic from TutorialsPoint"""
    # Clean topic name for URL
    topic_slug = topic.lower().replace(' ', '_')
    url = f"{base_url.rsplit('/', 1)[0]}/{topic_slug}.htm"
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
    }
    
    try:
        response = requests.get(url, headers=headers, timeout=10)
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # Get main content
            content_div = soup.find(['div', 'article'], class_=['tutorial-content', 'content'])
            if content_div:
                return content_div.get_text(strip=True)[:3000]
            
            # Fallback
            paragraphs = soup.find_all('p')[:10]
            content = ' '.join([p.get_text(strip=True) for p in paragraphs])
            return content[:3000] if content else None
    except Exception as e:
        pass
    
    return None

def generate_content_from_topic(topic, subject_name):
    """Generate basic educational content for a topic"""
    return f"""
## {topic}

{topic} is an important concept in {subject_name}. This topic covers the fundamental aspects 
and practical applications that are commonly tested in GTU examinations.

### Key Points:
- Understanding the basic definition and concepts of {topic}
- Implementation and practical applications
- Common problems and solutions
- Time and space complexity considerations (where applicable)

### Importance in GTU Exams:
This topic frequently appears in GTU examinations and students should focus on:
- Theoretical definitions and explanations
- Solved examples and derivations
- Practical coding implementations (for programming subjects)
- Previous year question patterns

### Study Resources:
- GeeksforGeeks tutorials
- TutorialsPoint guides
- NPTEL video lectures
- GTU previous year papers
"""

def scrape_and_save_subject(subject):
    """Scrape content for a subject and save to database"""
    print(f"\nðŸ“– Processing: {subject['name']} ({subject['code']})")
    
    total_saved = 0
    
    for i, topic in enumerate(subject['topics']):
        print(f"  â†’ [{i+1}/{len(subject['topics'])}] Scraping: {topic}")
        
        # Try GeeksforGeeks
        content = scrape_geeksforgeeks_topic(topic, subject['name'])
        source = "GeeksforGeeks"
        
        # If failed, try TutorialsPoint
        if not content and 'tutorialspoint' in subject['urls']:
            content = scrape_tutorialspoint_topic(topic, subject['name'], subject['urls']['tutorialspoint'])
            source = "TutorialsPoint"
        
        # If still no content, generate basic content
        if not content:
            content = generate_content_from_topic(topic, subject['name'])
            source = "AI-Generated (GTU Exam Prep)"
        
        # Determine unit number (group topics into 5 units)
        unit_number = (i // 3) + 1  # ~3 topics per unit
        
        # Save to syllabus_content table
        try:
            supabase.table('syllabus_content').insert({
                'subject_code': subject['code'],
                'unit': unit_number,
                'unit_title': f"Unit {unit_number}",
                'topic': topic,
                'content': content,
                'source_url': subject['urls'].get('geeksforgeeks', '')
            }).execute()
            
            print(f"    âœ“ Saved: {topic} (Unit {unit_number}) [{source}]")
            total_saved += 1
        except Exception as e:
            print(f"    âœ— Error saving {topic}: {e}")
        
        time.sleep(0.5)  # Rate limiting
    
    print(f"  âœ… Saved {total_saved} topics for {subject['name']}")
    return total_saved

def main():
    print("=" * 60)
    print("ðŸŽ“ GTU CE Semester 3 - Full Power Scraper")
    print("=" * 60)
    
    total = 0
    
    for subject in CE_SEM3_SUBJECTS:
        saved = scrape_and_save_subject(subject)
        total += saved
        time.sleep(1)  # Pause between subjects
    
    print("\n" + "=" * 60)
    print(f"âœ… Completed! Total {total} topics scraped and saved.")
    print("=" * 60)
    
    # Verify data
    print("\nðŸ“Š Verification - Topics per subject:")
    for subject in CE_SEM3_SUBJECTS:
        result = supabase.table('syllabus_content').select('*', count='exact').eq('subject_code', subject['code']).execute()
        print(f"  - {subject['name']}: {len(result.data)} topics")

if __name__ == "__main__":
    main()
